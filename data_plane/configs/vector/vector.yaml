# =============================================================================
# Vector Configuration - Data Plane Log Collection
# Collects from: Docker containers, gVisor audit logs, agent app logs
# Ships to: Control Plane API (CP-mediated log ingestion)
# =============================================================================

data_dir: /var/lib/vector

# =============================================================================
# SOURCES
# =============================================================================
sources:
  # Docker container logs (agent, envoy, coredns stdout/stderr)
  docker_logs:
    type: docker_logs
    include_containers:
      - "agent"
      - "envoy-proxy"
      - "dns-filter"
      - "agent-manager"

  # gVisor debug/audit logs (security-critical)
  # Requires runsc configured with: --debug-log=/var/log/runsc/
  gvisor_logs:
    type: file
    include:
      - /var/log/runsc/**/*.log
    read_from: beginning
    fingerprint:
      strategy: device_and_inode

  # Agent application logs (custom app logging)
  agent_app_logs:
    type: file
    include:
      - /var/log/agent/**/*.log
    read_from: end

# =============================================================================
# TRANSFORMS
# =============================================================================
transforms:
  # Parse Docker logs and extract metadata
  parse_docker:
    type: remap
    inputs:
      - docker_logs
    source: |
      # Extract container name
      container = get(.container_name) ?? "unknown"

      # Determine source from container name
      .source = if contains(string!(container), "envoy") {
        "envoy"
      } else if contains(string!(container), "agent-manager") {
        "agent-manager"
      } else if contains(string!(container), "agent") {
        "agent"
      } else if contains(string!(container), "dns") {
        "coredns"
      } else {
        "unknown"
      }

      # Set log type based on stream
      .log_type = if .stream == "stderr" { "stderr" } else { "stdout" }

      # Try to parse as JSON (Envoy access logs are JSON)
      msg = string(.message) ?? ""
      parsed, err = parse_json(msg)
      if err == null {
        # Envoy access log fields
        .method = get(parsed, "method") ?? ""
        .path = get(parsed, "path") ?? ""
        .upstream_host = get(parsed, "upstream_host") ?? ""
        .response_code = get(parsed, "response_code") ?? 0
        .duration_ms = get(parsed, "duration") ?? 0
        .bytes_sent = get(parsed, "bytes_sent") ?? 0
        .request_id = get(parsed, "request_id") ?? ""

        if .source == "envoy" && .method != "" {
          .log_type = "access"
        }
      }

      # Add metadata (agent_id is injected by CP from token)
      .hostname = get_env_var("HOSTNAME") ?? "unknown"
      .environment = get_env_var("ENVIRONMENT") ?? "development"

  # Parse gVisor logs (security audit)
  parse_gvisor:
    type: remap
    inputs:
      - gvisor_logs
    source: |
      .source = "gvisor"
      .hostname = get_env_var("HOSTNAME") ?? "unknown"
      .environment = get_env_var("ENVIRONMENT") ?? "development"

      msg = string(.message) ?? ""

      # Parse gVisor log format
      # Example: I0215 10:30:45.123456 12345 strace.go:123] [pid 1] openat(...)
      parsed, err = parse_regex(msg, r'^(?P<level>[IWEF])(?P<date>\d{4}) (?P<time>[\d:.]+)\s+(?P<pid>\d+)\s+(?P<file>[^:]+):(?P<line>\d+)\]\s*(?P<content>.*)$')

      if err == null {
        .level = if parsed.level == "I" { "info" }
                 else if parsed.level == "W" { "warning" }
                 else if parsed.level == "E" { "error" }
                 else { "fatal" }

        content = string(parsed.content) ?? ""

        # Extract syscall info if present
        syscall_match, serr = parse_regex(content, r'\[.*?\]\s+(?P<syscall>\w+)\(.*\)\s*=\s*(?P<result>.+)')
        if serr == null {
          .syscall = syscall_match.syscall
          result_str = string(syscall_match.result) ?? ""
          # Check if denied (EPERM, EACCES, etc.)
          .syscall_result = if contains(result_str, "EPERM") || contains(result_str, "EACCES") || contains(result_str, "denied") {
            "denied"
          } else if contains(result_str, "errno") {
            "error"
          } else {
            "allowed"
          }
          .log_type = "syscall"
        } else {
          .log_type = "audit"
        }
      } else {
        .log_type = "debug"
        .level = "info"
      }

  # Parse agent app logs
  parse_agent_app:
    type: remap
    inputs:
      - agent_app_logs
    source: |
      .source = "agent"
      .log_type = "app"
      .hostname = get_env_var("HOSTNAME") ?? "unknown"
      .environment = get_env_var("ENVIRONMENT") ?? "development"

      # Try JSON parsing
      msg = string(.message) ?? ""
      parsed, err = parse_json(msg)
      if err == null {
        .level = get(parsed, "level") ?? "info"
      } else {
        .level = "info"
      }

  # Combine all parsed logs
  all_logs:
    type: route
    inputs:
      - parse_docker
      - parse_gvisor
      - parse_agent_app
    route:
      security: '.source == "gvisor" && .syscall_result == "denied"'
      access: '.source == "envoy" && .log_type == "access"'
      _default: true

  # Format events for CP log ingestion API (POST /api/v1/logs/ingest)
  format_for_cp:
    type: remap
    inputs:
      - all_logs._default
      - all_logs.security
      - all_logs.access
    source: |
      # Save core fields expected by LogBatch schema
      ts = .timestamp
      msg = string!(.message)
      src = string(.source) ?? "unknown"
      lvl = string(.level) ?? "info"

      # Collect additional fields into extra
      extra = {}
      if exists(.log_type) { extra.log_type = .log_type }
      if exists(.hostname) { extra.hostname = .hostname }
      if exists(.environment) { extra.environment = .environment }
      if exists(.method) { extra.method = .method }
      if exists(.path) { extra.path = .path }
      if exists(.upstream_host) { extra.upstream_host = .upstream_host }
      if exists(.response_code) { extra.response_code = .response_code }
      if exists(.duration_ms) { extra.duration_ms = .duration_ms }
      if exists(.bytes_sent) { extra.bytes_sent = .bytes_sent }
      if exists(.request_id) { extra.request_id = .request_id }
      if exists(.syscall) { extra.syscall = .syscall }
      if exists(.syscall_result) { extra.syscall_result = .syscall_result }

      # Wrap in LogBatch schema: {"logs": [{...}]}
      # batch.max_events=1 ensures one LogBatch per request
      . = {"logs": [compact({"timestamp": ts, "message": msg, "source": src, "level": lvl, "extra": extra})]}

# =============================================================================
# SINKS
# =============================================================================
sinks:
  # Primary: Control Plane API (CP-mediated log ingestion)
  # CP injects agent_id and tenant_id from the bearer token, preventing
  # a compromised data plane from spoofing identity or tampering with logs.
  control_plane:
    type: http
    inputs:
      - format_for_cp
    uri: "${CONTROL_PLANE_URL}/api/v1/logs/ingest"
    method: post
    encoding:
      codec: json
    auth:
      strategy: bearer
      token: "${CONTROL_PLANE_TOKEN}"
    batch:
      max_events: 1
      timeout_secs: 5
    request:
      headers:
        Content-Type: application/json
      rate_limit_num: 80
      rate_limit_duration_secs: 60
      retry_initial_backoff_secs: 5
      retry_max_duration_secs: 60

  # Local file backup (if CP API unreachable)
  file_backup:
    type: file
    inputs:
      - format_for_cp
    path: /var/log/vector/backup/%Y-%m-%d.log
    encoding:
      codec: json
